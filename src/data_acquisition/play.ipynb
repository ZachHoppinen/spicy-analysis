{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from itertools import product\n",
    "# from tqdm.contrib.itertools import product\n",
    "\n",
    "def get_stats(a, b):\n",
    "    r, p = pearsonr(a, b)\n",
    "    error = mae(a, b)\n",
    "    rmse = mean_squared_error(a, b, squared=False)\n",
    "    bias = np.mean(a - b)\n",
    "    return r, error, rmse, bias\n",
    "\n",
    "\n",
    "def make_stat_da(iter_num, loc_fp):\n",
    "    \n",
    "    param_fps = list(param_fp.glob('*'))[0]\n",
    "    stems= [f.stem for f in list(param_fps.glob('*_*_*.npy'))]\n",
    "    A = np.unique([s.split('_')[0] for s in stems])\n",
    "    B = np.unique([s.split('_')[1] for s in stems])\n",
    "    C = np.unique([s.split('_')[2] for s in stems])\n",
    "    iterations = np.arange(iter_num)\n",
    "\n",
    "    print(f'Starting {loc_fp.stem}')\n",
    "    res = np.zeros((1, len(A), len(B), len(C), len(iterations)))\n",
    "\n",
    "    da = xr.DataArray(res, coords = [[loc_fp.stem], A, B, C, iterations], dims = ['location', 'A', 'B','C', 'iteration'], name = 'pearsonr')\n",
    "    res_ds = xr.merge([da, da.copy().rename('mae'), da.copy().rename('rmse'), da.copy().rename('bias')])\n",
    "\n",
    "    lidar_orig = np.load(loc_fp.joinpath('lidar.npy'))\n",
    "    elev = np.load(loc_fp.joinpath('elev.npy'))\n",
    "    trees = np.load(loc_fp.joinpath('trees.npy'))\n",
    "\n",
    "    idx = (trees < 0.5) & (elev > 2000)\n",
    "\n",
    "    for a, b, c in product(A, B, C):\n",
    "        sds_orig = np.load(loc_fp.joinpath(f'{a}_{b}_{c}.npy'))\n",
    "        combo = np.vstack([lidar_orig, sds_orig])\n",
    "        combo = combo.T[idx].T\n",
    "        for iter in iterations:\n",
    "            id_iter = np.random.choice(combo.shape[1], combo.shape[1], replace = True)\n",
    "            sds, lidar = combo.T[id_iter].T\n",
    "            r, mean_error, rmse, bias = get_stats(lidar, sds)\n",
    "            res_ds['pearsonr'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c, iteration = iter)] = r\n",
    "            res_ds['mae'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c, iteration = iter)] = mean_error\n",
    "            res_ds['rmse'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c, iteration = iter)] = rmse\n",
    "            res_ds['bias'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c, iteration = iter)] = bias\n",
    "    \n",
    "    res_ds.to_netcdf(loc_fp.parent.joinpath(loc_fp.stem + '.nc'))\n",
    "\n",
    "\n",
    "out_fp = Path('/bsuhome/zacharykeskinen/scratch/spicy/param_stats.nc')\n",
    "\n",
    "if out_fp.exists():\n",
    "    print('Already exists...')\n",
    "    # res_ds = xr.load_dataset(out_fp)\n",
    "\n",
    "\n",
    "param_fp = Path('/bsuhome/zacharykeskinen/scratch/spicy/param_npys')\n",
    "\n",
    "locs = list(param_fp.glob('*'))\n",
    "locs = [l.stem for l in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Mores_2021-03-15\n",
      "Starting Dry_Creek_2020-02-19Starting Little_Cottonwood_2021-03-18\n",
      "Starting Banner_2021-03-15\n",
      "\n",
      "Starting Mores_2020-02-09Starting Frasier_2021-03-19\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pool \u001b[39m=\u001b[39m Pool()\n\u001b[0;32m----> 3\u001b[0m pool\u001b[39m.\u001b[39;49mmap(partial(make_stat_da, \u001b[39m10\u001b[39;49m), param_fp\u001b[39m.\u001b[39;49mglob(\u001b[39m'\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pool = Pool()\n",
    "    \n",
    "pool.map(partial(make_stat_da, 10), param_fp.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
