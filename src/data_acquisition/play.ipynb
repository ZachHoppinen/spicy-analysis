{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "# from tqdm.contrib.itertools import product\n",
    "\n",
    "def get_stats(a, b):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\"An input array is constant\")\n",
    "        r, p = pearsonr(a, b)\n",
    "    error = mae(a, b)\n",
    "    rmse = mean_squared_error(a, b, squared=False)\n",
    "    bias = np.mean(a - b)\n",
    "    return r, error, rmse, bias\n",
    "\n",
    "\n",
    "def make_stat_da(tree_idx_low, tree_idx_high, loc_fp):\n",
    "    \n",
    "    print(f'Starting {loc_fp.stem}...')\n",
    "\n",
    "    stems= [f.stem for f in list(loc_fp.glob('*_*_*.npy'))]\n",
    "\n",
    "    A = np.unique([float(s.split('_')[0]) for s in stems])\n",
    "    B = np.unique([float(s.split('_')[1]) for s in stems])\n",
    "    C = np.unique([float(s.split('_')[2]) for s in stems])\n",
    "\n",
    "    res = np.zeros((1, len(A), len(B), len(C)))\n",
    "\n",
    "    da = xr.DataArray(res, coords = [[loc_fp.stem], A, B, C], dims = ['location', 'A', 'B','C'], name = 'pearsonr')\n",
    "    res_ds = xr.merge([da, da.copy().rename('mae'), da.copy().rename('rmse'), da.copy().rename('bias')])\n",
    "\n",
    "    lidar_orig = np.load(loc_fp.joinpath('lidar.npy'))\n",
    "    elev = np.load(loc_fp.joinpath('elev.npy'))\n",
    "    trees = np.load(loc_fp.joinpath('trees.npy'))\n",
    "\n",
    "    idx = (trees <= tree_idx_high) & (elev > 0) & (trees >= tree_idx_low)\n",
    "    print(idx)\n",
    "    print(A)\n",
    "\n",
    "    if 'Cottonwood' in loc_fp.stem:\n",
    "        print(f\"Size of datarray: {res_ds['pearsonr'].data.shape}\")\n",
    "        print(f'Used fraction: {np.sum(idx)/elev.size}')\n",
    "\n",
    "    for a, b, c in product(A, B, C):\n",
    "        sds_orig = np.load(loc_fp.joinpath(f'{a}_{b}_{c}.npy'))\n",
    "        combo = np.vstack([lidar_orig, sds_orig])\n",
    "        combo = combo.T[idx].T\n",
    "\n",
    "        sds, lidar = combo\n",
    "        r, mean_error, rmse, bias = get_stats(lidar, sds)\n",
    "        res_ds['pearsonr'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c)] = r\n",
    "        res_ds['mae'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c)] = mean_error\n",
    "        res_ds['rmse'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c)] = rmse\n",
    "        res_ds['bias'].loc[dict(location = loc_fp.stem, A = a, B = b, C = c)] = bias\n",
    "    \n",
    "    for dv in res_ds.data_vars:\n",
    "        res_ds[dv] = res_ds[dv].astype(float)\n",
    "    res_ds.to_netcdf(loc_fp.parent.joinpath('stats_ncs', loc_fp.stem + f'{tree_idx_low}_{tree_idx_high}_stats.nc'))\n",
    "\n",
    "    print(f'Finishing {loc_fp.stem}!')\n",
    "\n",
    "\n",
    "param_fp = Path('/bsuhome/zacharykeskinen/scratch/spicy/param_npys')\n",
    "\n",
    "param_fp.joinpath('stats_ncs').mkdir(exist_ok = True)\n",
    "\n",
    "\n",
    "out_fp = Path('/bsuhome/zacharykeskinen/scratch/spicy/param_stats.nc')\n",
    "\n",
    "if out_fp.exists():\n",
    "    print('Already exists...')\n",
    "\n",
    "# pool = Pool()\n",
    "    \n",
    "# pool.map(partial(make_stat_da, 0, 1), param_fp.glob('*_*-*-*'))\n",
    "# das = [xr.open_dataset(fp) for fp in param_fp.joinpath('stats_ncs').glob('*0_1_stats.nc')]\n",
    "# ds = xr.merge(das)\n",
    "# ds.to_netcdf(param_fp.joinpath('param_stats_all.nc'))\n",
    "\n",
    "# pool = Pool()\n",
    "# pool.map(partial(make_stat_da, 0, 0.25), param_fp.glob('*_*-*-*'))\n",
    "# das = [xr.open_dataset(fp) for fp in param_fp.joinpath('stats_ncs').glob('*0_0.25_stats.nc')]\n",
    "# ds = xr.merge(das)\n",
    "# ds.to_netcdf(param_fp.joinpath('param_stats_low_fcf.nc'))\n",
    "\n",
    "# pool = Pool()\n",
    "# pool.map(partial(make_stat_da, 0.75, 1), param_fp.glob('*_*-*-*'))\n",
    "# das = [xr.open_dataset(fp) for fp in param_fp.joinpath('stats_ncs').glob('*0_0.25_stats.nc')]\n",
    "# ds = xr.merge(das)\n",
    "# ds.to_netcdf(param_fp.joinpath('param_stats_high_fcf.nc'))\n",
    "\n",
    "# # locs = list(param_fp.glob('*'))\n",
    "# # locs = [l.stem for l in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Mores_2021-03-15...\n",
      "[ True  True  True ...  True  True  True]\n",
      "[1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7\n",
      " 2.8 2.9 3. ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m make_stat_da(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39mnext\u001b[39;49m(param_fp\u001b[39m.\u001b[39;49mglob(\u001b[39m'\u001b[39;49m\u001b[39m*_*-*-*\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n",
      "\u001b[1;32m/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUsed fraction: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39msum(idx)\u001b[39m/\u001b[39melev\u001b[39m.\u001b[39msize\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mfor\u001b[39;00m a, b, c \u001b[39min\u001b[39;00m product(A, B, C):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     sds_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(loc_fp\u001b[39m.\u001b[39;49mjoinpath(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00ma\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mb\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mc\u001b[39m}\u001b[39;49;00m\u001b[39m.npy\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     combo \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack([lidar_orig, sds_orig])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/data_acquisition/play.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     combo \u001b[39m=\u001b[39m combo\u001b[39m.\u001b[39mT[idx]\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/site-packages/numpy/lib/npyio.py:412\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    410\u001b[0m _ZIP_SUFFIX \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPK\u001b[39m\u001b[39m\\x05\u001b[39;00m\u001b[39m\\x06\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    411\u001b[0m N \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 412\u001b[0m magic \u001b[39m=\u001b[39m fid\u001b[39m.\u001b[39mread(N)\n\u001b[1;32m    413\u001b[0m \u001b[39m# If the file size is less than N, we need to make sure not\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m# to seek past the beginning of the file\u001b[39;00m\n\u001b[1;32m    415\u001b[0m fid\u001b[39m.\u001b[39mseek(\u001b[39m-\u001b[39m\u001b[39mmin\u001b[39m(N, \u001b[39mlen\u001b[39m(magic)), \u001b[39m1\u001b[39m)  \u001b[39m# back-up\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "make_stat_da(0, 1, next(param_fp.glob('*_*-*-*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/bsuhome/zacharykeskinen/scratch/spicy/param_npys')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_fp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
