{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from spicy_snow.retrieval import retrieval_from_parameters\n",
    "\n",
    "# import functions for downloading\n",
    "from spicy_snow.download.sentinel1 import s1_img_search, hyp3_pipeline, download_hyp3, combine_s1_images\n",
    "from spicy_snow.download.forest_cover import download_fcf\n",
    "from spicy_snow.download.snow_cover import download_snow_cover\n",
    "\n",
    "# import functions for pre-processing\n",
    "from spicy_snow.processing.s1_preprocessing import merge_partial_s1_images, s1_orbit_averaging,\\\n",
    "s1_clip_outliers, subset_s1_images, ims_water_mask, s1_incidence_angle_masking, merge_s1_subsets\n",
    "\n",
    "# import the functions for snow_index calculation\n",
    "from spicy_snow.processing.snow_index import calc_delta_VV, calc_delta_cross_ratio, \\\n",
    "    calc_delta_gamma, clip_delta_gamma_outlier, calc_snow_index, calc_snow_index_to_snow_depth\n",
    "\n",
    "# import the functions for wet snow flag\n",
    "from spicy_snow.processing.wet_snow import id_newly_frozen_snow, id_newly_wet_snow, \\\n",
    "    id_wet_negative_si, flag_wet_snow\n",
    "\n",
    "# setup root logger\n",
    "from spicy_snow.utils.spicy_logging import setup_logging\n",
    "\n",
    "# fischer z test\n",
    "from causallearn.utils.cit import CIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = Path('~/scratch/spicy/SnowEx-Data/').expanduser().resolve()\n",
    "data_dir = Path('~/scratch/spicy/SnowEx-Data/').expanduser().resolve()\n",
    "dss = {fp.stem: xr.open_dataset(fp) for fp in in_dir.glob('*.nc')}\n",
    "\n",
    "# Create parameter space\n",
    "A = np.round(np.arange(1, 3.1, 0.5), 2)\n",
    "B = np.round(np.arange(0, 2.01, 0.25), 2)\n",
    "C = np.round(np.arange(0.25, 1.001, 0.25), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s1_to_sd(ds, A = 1.5, B = 0.1, C = 0.6):\n",
    "    # mask out outliers in incidence angle\n",
    "    ds = s1_incidence_angle_masking(ds)\n",
    "    \n",
    "    # subset dataset by flight_dir and platform\n",
    "    dict_ds = subset_s1_images(ds)\n",
    "\n",
    "    for subset_name, subset_ds in dict_ds.items():\n",
    "        # average each orbit to overall mean\n",
    "        dict_ds[subset_name] = s1_orbit_averaging(subset_ds)\n",
    "        # clip outlier values of backscatter to overall mean\n",
    "        dict_ds[subset_name] = s1_clip_outliers(subset_ds)\n",
    "    \n",
    "    # recombine subsets\n",
    "    ds = merge_s1_subsets(dict_ds)\n",
    "\n",
    "    # calculate confidence interval\n",
    "    # ds = add_confidence_angle(ds)\n",
    "\n",
    "    ## Snow Index Steps\n",
    "    # log.info(\"Calculating snow index\")\n",
    "    # calculate delta CR and delta VV\n",
    "    ds = calc_delta_cross_ratio(ds, A = A)\n",
    "    ds = calc_delta_VV(ds)\n",
    "\n",
    "    # calculate delta gamma with delta CR and delta VV with FCF\n",
    "    ds = calc_delta_gamma(ds, B = B)\n",
    "\n",
    "    # clip outliers of delta gamma\n",
    "    ds = clip_delta_gamma_outlier(ds)\n",
    "\n",
    "    # calculate snow_index from delta_gamma\n",
    "    ds = calc_snow_index(ds, ims_masking = True)\n",
    "\n",
    "    # convert snow index to snow depth\n",
    "    ds = calc_snow_index_to_snow_depth(ds, C = C)\n",
    "\n",
    "    return ds\n",
    "\n",
    "import warnings\n",
    "def get_gaussian_stats(da):\n",
    "    arr = da.values\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Degrees of freedom <= 0 \")\n",
    "    return arr.size, np.nanmean(arr), np.nanstd(arr), arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(x, y): return np.mean(x - y)\n",
    "\n",
    "def get_stats(x, y, nrmse = False):\n",
    "    if type(x) == xr.DataArray: x = x.values.ravel()\n",
    "    if type(y) == xr.DataArray: y = y.values.ravel()\n",
    "    if type(x) == list: x = np.array(x)\n",
    "    if type(y) == list: y = np.array(y)\n",
    "    idx = (~np.isnan(x)) & (~np.isnan(y))\n",
    "    x, y = x[idx], y[idx]\n",
    "    r, p = pearsonr(x, y)\n",
    "    b = bias(x, y)\n",
    "    mae = mean_absolute_error(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared = False)\n",
    "\n",
    "    if nrmse:\n",
    "        nrmse_value = rmse / np.mean(x)\n",
    "        return r, b, mae, rmse, nrmse_value\n",
    "\n",
    "    return r, b, mae, rmse\n",
    "\n",
    "from scipy.stats import norm\n",
    "def fischerz(truth, x1, x2):\n",
    "    idx = (~np.isnan(truth)) & (~np.isnan(x1)) & (~np.isnan(x2))\n",
    "    truth, x1, x2 = truth[idx], x1[idx], x2[idx]\n",
    "    n = len(x1)\n",
    "    cor1 = pearsonr(truth, x1).statistic\n",
    "    cor2 = pearsonr(truth, x2).statistic\n",
    "    fischer1 = 0.5*np.log((1+cor1)/(1-cor1))\n",
    "    fischer2 = 0.5*np.log((1+cor2)/(1-cor2))\n",
    "    expected_sd = np.sqrt(1/(n-3))\n",
    "    return 2 * (1 - norm(0, expected_sd).cdf(np.abs(fischer1 - fischer2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# incidence angel random field with parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mores 2020\n",
      "S1: R: 0.08426767662873491. RMSE: 1.0739974121237865. RANDOM: R: 0.1505348795647083 RMSE: 1.4093288033084126. FischerZ: 0.0001242480417045222\n",
      "Fraser 2021\n",
      "S1: R: 0.18382002487927696. RMSE: 0.6541369851067282. RANDOM: R: 0.10667524188054645 RMSE: 0.7513895781508385. FischerZ: 0.0005879646394355564\n",
      "Dry Creek 2020\n",
      "S1: R: 0.20510866035642356. RMSE: 0.7382410700288716. RANDOM: R: 0.06621667487901962 RMSE: 0.9229266598088253. FischerZ: 0.0\n",
      "Banner 2021\n",
      "S1: R: 0.41537871427426587. RMSE: 0.8915869451365991. RANDOM: R: 0.09440825698128871 RMSE: 1.052883594648055. FischerZ: 0.0\n",
      "Little Cottonwood 2021\n",
      "S1: R: 0.5397881461260303. RMSE: 1.065947341300313. RANDOM: R: 0.11148637741974951 RMSE: 1.2961281002120792. FischerZ: 0.0\n",
      "Mores 2021\n",
      "S1: R: 0.39756464003682557. RMSE: 0.9145271045588742. RANDOM: R: 0.005409224595314001 RMSE: 1.180942715143895. FischerZ: 0.0\n",
      "Banner 2020\n",
      "S1: R: 0.40022758224160293. RMSE: 0.9950183007831572. RANDOM: R: 0.23595462256583005 RMSE: 1.2194473555172656. FischerZ: 0.0\n",
      "Fraser 2020\n",
      "S1: R: 0.38149097946780053. RMSE: 0.9250319335954182. RANDOM: R: 0.2239838809391825 RMSE: 0.9778128220361906. FischerZ: 1.3543132282300974e-07\n",
      "Cameron 2021\n",
      "S1: R: 0.015191728832118374. RMSE: 1.0666044459623203. RANDOM: R: -0.09004210282821709 RMSE: 1.1117434576074416. FischerZ: 1.8306684109736793e-05\n"
     ]
    }
   ],
   "source": [
    "for stem, full_ds in dss.items():\n",
    "\n",
    "    if stem == 'Frasier_2020-02-11':\n",
    "        im_date = pd.to_datetime('2020-02-16')\n",
    "    else:\n",
    "        im_date = pd.to_datetime(full_ds.sel(time = full_ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "\n",
    "    d_days = im_date - pd.to_datetime(full_ds.attrs['lidar-flight-time'])\n",
    "    site_name = stem.replace('_', ' ').replace('Frasier', 'Fraser').split('-')[0]\n",
    "    # if site_name == 'Mores 2020' or site_name == 'Fraser 2021' or site_name == 'Dry Creek 2020' or site_name == 'Banner 2021' or site_name == 'Little Cottonwood 2021' or\\\n",
    "    #     site_name == 'Mores 2021' or site_name == 'Banner 2020':\n",
    "    #     continue\n",
    "\n",
    "    # create random dataset of VV and VH\n",
    "    r_ds = full_ds.copy(deep = True)\n",
    "    for ts in r_ds.time:\n",
    "        inc = full_ds.sel(time = ts, band = 'inc')['s1']\n",
    "        for band in ['VV', 'VH']:\n",
    "            for inc_low, inc_high in [[0, 10], [10, 20], [20, 30], [30, 40], [40, 50], [50, 60], [60, 70]]:\n",
    "                inc_low, inc_high = np.deg2rad(inc_low), np.deg2rad(inc_high)\n",
    "                n, u, std, shape = get_gaussian_stats(full_ds['s1'].sel(band = band, time = ts).where((inc > inc_low) & (inc < inc_high)))\n",
    "                rand = np.random.normal(size = full_ds['lidar-sd'].size, loc = u, scale = std).reshape(full_ds['lidar-sd'].shape)\n",
    "                r_ds['s1'].loc[dict(time = ts, band = band)] = r_ds['s1'].loc[dict(time = ts, band = band)].where((inc > inc_low) & (inc < inc_high), rand)\n",
    "    \n",
    "    # holds rmse and r for optimizing rand dataset\n",
    "    rand_rmse_ds = xr.DataArray(np.zeros([len(A), len(B), len(C)]), dims = ['A', 'B', 'C'], coords = [A, B, C])\n",
    "    rand_r_ds = xr.DataArray(np.zeros([len(A), len(B), len(C)]), dims = ['A', 'B', 'C'], coords = [A, B, C])\n",
    "\n",
    "    optimize random dataset\n",
    "    for a in A:\n",
    "        for b in B:\n",
    "            for c in C:\n",
    "                r_ds = s1_to_sd(r_ds, A = a, B = b, C = c)\n",
    "                rand_r, rand_b, rand_mae, rand_rmse, rand_nrmse = get_stats(r_ds['snow_depth'].sel(time = im_date, method = 'nearest'), r_ds['lidar-sd'], nrmse = True)\n",
    "                rand_rmse_ds.loc[dict(A = a, B = b, C = C)] = rand_rmse\n",
    "                rand_r_ds.loc[dict(A = a, B = b, C = C)] = rand_r\n",
    "    \n",
    "    # get parameters\n",
    "    a_best = rand_r_ds.max(['B', 'C']).idxmax('A')\n",
    "    b_best = rand_r_ds.max(['C', 'A']).idxmax('B')\n",
    "    c_best = rand_rmse_ds.sel(A = a_best, B = b_best).idxmin('C')\n",
    "    print(f\"A: {a_best.data.ravel()[0]} B: {b_best.data.ravel()[0]} C: {c_best.data.ravel()[0]}\")\n",
    "    # a_best, b_best, c_best = 1, 0.0, 0.25\n",
    "\n",
    "    r_ds = s1_to_sd(r_ds, A= a_best, B = b_best, C = c_best).sel(time = im_date, method = 'nearest')\n",
    "    ds = full_ds.sel(time = im_date, method = 'nearest')\n",
    "\n",
    "    # print values\n",
    "    print(site_name)\n",
    "\n",
    "    r, b, mae, rmse, nrmse = get_stats(ds['snow_depth'], ds['lidar-sd'], nrmse = True)\n",
    "    rand_r, rand_b, rand_mae, rand_rmse, rand_nrmse = get_stats(r_ds['snow_depth'], r_ds['lidar-sd'], nrmse = True)\n",
    "    fischer_z = fischerz(ds['lidar-sd'].data.ravel(), ds['snow_depth'].data.ravel(), r_ds['snow_depth'].data.ravel())\n",
    "\n",
    "    print(f'S1: R: {r}. RMSE: {rmse}. RANDOM: R: {rand_r_ds.sel(A = a_best, B = b_best, C = c_best).data.ravel()[0]} RMSE: {rand_rmse_ds.sel(A = a_best, B = b_best, C = c_best).data.ravel()[0]}. FischerZ: {fischer_z}')\n",
    "    # print(f'S1: R: {r}. RMSE: {rmse}. RANDOM: R: {rand_r} RMSE: {rand_rmse}. FischerZ: {fischer_z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all sites combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mores 2020\n",
      "PearsonRResult(statistic=0.12213905729392673, pvalue=3.181663272479397e-14)\n",
      "3836\n",
      "PearsonRResult(statistic=0.12213905729392673, pvalue=3.181663272479397e-14)\n",
      "Fraser 2021\n",
      "PearsonRResult(statistic=0.12349825108791976, pvalue=2.1379287495439696e-25)\n",
      "10895\n",
      "PearsonRResult(statistic=0.3959287495208208, pvalue=0.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/bsuhome/zacharykeskinen/spicy-analysis/src/compare/overall/random_field_table.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/compare/overall/random_field_table.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m inc_low, inc_high \u001b[39min\u001b[39;00m [[\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m], [\u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m], [\u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m], [\u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m], [\u001b[39m40\u001b[39m, \u001b[39m50\u001b[39m], [\u001b[39m50\u001b[39m, \u001b[39m60\u001b[39m], [\u001b[39m60\u001b[39m, \u001b[39m70\u001b[39m]]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/compare/overall/random_field_table.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     inc_low, inc_high \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdeg2rad(inc_low), np\u001b[39m.\u001b[39mdeg2rad(inc_high)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/compare/overall/random_field_table.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     n, u, std, shape \u001b[39m=\u001b[39m get_gaussian_stats(full_ds[\u001b[39m'\u001b[39m\u001b[39ms1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msel(band \u001b[39m=\u001b[39m band, time \u001b[39m=\u001b[39m ts)\u001b[39m.\u001b[39mwhere((inc \u001b[39m>\u001b[39;49m inc_low) \u001b[39m&\u001b[39m (inc \u001b[39m<\u001b[39m inc_high)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/compare/overall/random_field_table.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     rand \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(size \u001b[39m=\u001b[39m full_ds[\u001b[39m'\u001b[39m\u001b[39mlidar-sd\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msize, loc \u001b[39m=\u001b[39m u, scale \u001b[39m=\u001b[39m std)\u001b[39m.\u001b[39mreshape(full_ds[\u001b[39m'\u001b[39m\u001b[39mlidar-sd\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bborah/bsuhome/zacharykeskinen/spicy-analysis/src/compare/overall/random_field_table.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     r_ds[\u001b[39m'\u001b[39m\u001b[39ms1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mloc[\u001b[39mdict\u001b[39m(time \u001b[39m=\u001b[39m ts, band \u001b[39m=\u001b[39m band)] \u001b[39m=\u001b[39m r_ds[\u001b[39m'\u001b[39m\u001b[39ms1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mloc[\u001b[39mdict\u001b[39m(time \u001b[39m=\u001b[39m ts, band \u001b[39m=\u001b[39m band)]\u001b[39m.\u001b[39mwhere((inc \u001b[39m>\u001b[39m inc_low) \u001b[39m&\u001b[39m (inc \u001b[39m<\u001b[39m inc_high) \u001b[39m&\u001b[39m (\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(full_ds[\u001b[39m'\u001b[39m\u001b[39ms1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msel(time \u001b[39m=\u001b[39m ts, band \u001b[39m=\u001b[39m band))), rand)\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/site-packages/xarray/core/_typed_ops.py:242\u001b[0m, in \u001b[0;36mDataArrayOpsMixin.__gt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__gt__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_binary_op(other, operator\u001b[39m.\u001b[39;49mgt)\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/site-packages/xarray/core/dataarray.py:4355\u001b[0m, in \u001b[0;36mDataArray._binary_op\u001b[0;34m(self, other, f, reflexive)\u001b[0m\n\u001b[1;32m   4351\u001b[0m other_variable \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(other, \u001b[39m\"\u001b[39m\u001b[39mvariable\u001b[39m\u001b[39m\"\u001b[39m, other)\n\u001b[1;32m   4352\u001b[0m other_coords \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(other, \u001b[39m\"\u001b[39m\u001b[39mcoords\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   4354\u001b[0m variable \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 4355\u001b[0m     f(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariable, other_variable)\n\u001b[1;32m   4356\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reflexive\n\u001b[1;32m   4357\u001b[0m     \u001b[39melse\u001b[39;00m f(other_variable, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariable)\n\u001b[1;32m   4358\u001b[0m )\n\u001b[1;32m   4359\u001b[0m coords, indexes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoords\u001b[39m.\u001b[39m_merge_raw(other_coords, reflexive)\n\u001b[1;32m   4360\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_name(other)\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/site-packages/xarray/core/_typed_ops.py:432\u001b[0m, in \u001b[0;36mVariableOpsMixin.__gt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__gt__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_binary_op(other, operator\u001b[39m.\u001b[39;49mgt)\n",
      "File \u001b[0;32m~/miniconda3/envs/spicy/lib/python3.11/site-packages/xarray/core/variable.py:2654\u001b[0m, in \u001b[0;36mVariable._binary_op\u001b[0;34m(self, other, f, reflexive)\u001b[0m\n\u001b[1;32m   2651\u001b[0m attrs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attrs \u001b[39mif\u001b[39;00m keep_attrs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   2653\u001b[0m     new_data \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 2654\u001b[0m         f(self_data, other_data) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reflexive \u001b[39melse\u001b[39;00m f(other_data, self_data)\n\u001b[1;32m   2655\u001b[0m     )\n\u001b[1;32m   2656\u001b[0m result \u001b[39m=\u001b[39m Variable(dims, new_data, attrs\u001b[39m=\u001b[39mattrs)\n\u001b[1;32m   2657\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sd = []\n",
    "s1 = []\n",
    "rands = []\n",
    "for stem, full_ds in dss.items():\n",
    "\n",
    "    if stem == 'Frasier_2020-02-11':\n",
    "        im_date = pd.to_datetime('2020-02-16')\n",
    "    else:\n",
    "        im_date = pd.to_datetime(full_ds.sel(time = full_ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "\n",
    "    d_days = im_date - pd.to_datetime(full_ds.attrs['lidar-flight-time'])\n",
    "    site_name = stem.replace('_', ' ').replace('Frasier', 'Fraser').split('-')[0]\n",
    "    # if site_name == 'Mores 2020' or site_name == 'Fraser 2021' or site_name == 'Dry Creek 2020' or site_name == 'Banner 2021' or site_name == 'Little Cottonwood 2021' or\\\n",
    "    #     site_name == 'Mores 2021' or site_name == 'Banner 2020':\n",
    "    #     continue\n",
    "\n",
    "    # create random dataset of VV and VH\n",
    "    r_ds = full_ds[['s1','fcf','ims']].copy(deep = True)\n",
    "    for ts in r_ds.time:\n",
    "        inc = full_ds.sel(time = ts, band = 'inc')['s1']\n",
    "        for band in ['VV', 'VH']:\n",
    "            for inc_low, inc_high in [[0, 10], [10, 20], [20, 30], [30, 40], [40, 50], [50, 60], [60, 70]]:\n",
    "                inc_low, inc_high = np.deg2rad(inc_low), np.deg2rad(inc_high)\n",
    "                n, u, std, shape = get_gaussian_stats(full_ds['s1'].sel(band = band, time = ts).where((inc > inc_low) & (inc < inc_high)))\n",
    "                rand = np.random.normal(size = full_ds['lidar-sd'].size, loc = u, scale = std).reshape(full_ds['lidar-sd'].shape)\n",
    "                r_ds['s1'].loc[dict(time = ts, band = band)] = r_ds['s1'].loc[dict(time = ts, band = band)].where((inc > inc_low) & (inc < inc_high) & (~np.isnan(full_ds['s1'].sel(time = ts, band = band))), rand)\n",
    "    \n",
    "    # holds rmse and r for optimizing rand dataset\n",
    "    # rand_rmse_ds = xr.DataArray(np.zeros([len(A), len(B), len(C)]), dims = ['A', 'B', 'C'], coords = [A, B, C])\n",
    "    # rand_r_ds = xr.DataArray(np.zeros([len(A), len(B), len(C)]), dims = ['A', 'B', 'C'], coords = [A, B, C])\n",
    "\n",
    "    # # optimize random dataset\n",
    "    # for a in A:\n",
    "    #     for b in B:\n",
    "    #         for c in C:\n",
    "    #             r_ds = s1_to_sd(r_ds, A = a, B = b, C = c)\n",
    "    #             rand_r, rand_b, rand_mae, rand_rmse, rand_nrmse = get_stats(r_ds['snow_depth'].sel(time = im_date, method = 'nearest'), r_ds['lidar-sd'], nrmse = True)\n",
    "    #             rand_rmse_ds.loc[dict(A = a, B = b, C = C)] = rand_rmse\n",
    "    #             rand_r_ds.loc[dict(A = a, B = b, C = C)] = rand_r\n",
    "    \n",
    "    # get parameters\n",
    "    # a_best = rand_r_ds.max(['B', 'C']).idxmax('A')\n",
    "    # b_best = rand_r_ds.max(['C', 'A']).idxmax('B')\n",
    "    # c_best = rand_rmse_ds.sel(A = a_best, B = b_best).idxmin('C')\n",
    "    # print(f\"A: {a_best.data.ravel()[0]} B: {b_best.data.ravel()[0]} C: {c_best.data.ravel()[0]}\")\n",
    "    best_a, best_b, best_c = 1, 0.0, 0.25\n",
    "    r_ds = s1_to_sd(r_ds[['s1','ims','fcf']], A= best_a, B = best_b, C = best_c).sel(time = im_date, method = 'nearest')\n",
    "    ds = full_ds.sel(time = im_date, method = 'nearest')\n",
    "    x1, x2 = r_ds['snow_depth'].data.ravel(), ds['lidar-sd'].data.ravel()\n",
    "    idx = (~np.isnan(x1)) & (~np.isnan(x2))\n",
    "    print(site_name)\n",
    "    print(pearsonr(x1[idx], x2[idx]))\n",
    "\n",
    "    rands.append(r_ds['snow_depth'].data.ravel())\n",
    "    # print(np.concatenate(rands).size)\n",
    "    s1.append(ds['snow_depth'].data.ravel())\n",
    "    sd.append(ds['lidar-sd'].data.ravel())\n",
    "    x1, x2 = np.concatenate(rands), np.concatenate(sd)\n",
    "    idx = (~np.isnan(x1)) & (~np.isnan(x2))\n",
    "    print(np.sum(idx))\n",
    "\n",
    "    print(pearsonr(x1[idx], x2[idx]))\n",
    "\n",
    "rands, s1, sd = np.concatenate(rands), np.concatenate(s1), np.concatenate(sd)\n",
    "r, b, mae, rmse, nrmse = get_stats(s1, sd, nrmse = True)\n",
    "rand_r, rand_b, rand_mae, rand_rmse, rand_nrmse = get_stats(rands, sd, nrmse = True)\n",
    "fischer_z = fischerz(sd, s1, rands)\n",
    "\n",
    "print(f'S1: R: {r}. RMSE: {rmse}. RANDOM: R: {rand_r} RMSE: {rand_rmse}. FischerZ: {fischer_z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17250"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rands[0].size + rands[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17250"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(rands).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no incidence angle accounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stem, full_ds in dss.items():\n",
    "    # fig, axes = plt.subplots(1,4, figsize = (12, 8))\n",
    "    # im_time = ds.attrs['lidar-flight-time']\n",
    "    # ds['snow_index'].sel(time = im_time, method = 'nearest').where(~ds['lidar-sd'].isnull()).plot(ax = axes[0])\n",
    "    # r_ds['snow_index'].sel(time = im_time, method = 'nearest').where(~ds['lidar-sd'].isnull()).plot(ax = axes[1])\n",
    "    # ds['lidar-sd'].plot(ax = axes[2])\n",
    "    # ds['lidar-dem'].plot(ax = axes[3])\n",
    "\n",
    "    if stem == 'Frasier_2020-02-11':\n",
    "        im_date = pd.to_datetime('2020-02-16')\n",
    "    else:\n",
    "        im_date = pd.to_datetime(full_ds.sel(time = full_ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "\n",
    "    d_days = im_date - pd.to_datetime(full_ds.attrs['lidar-flight-time'])\n",
    "    site_name = stem.replace('_', ' ').replace('Frasier', 'Fraser').split('-')[0]\n",
    "\n",
    "    r_ds = full_ds.copy(deep = True)\n",
    "    for ts in r_ds.time:\n",
    "        for band in ['VV', 'VH']:\n",
    "            n, u, std, shape = get_gaussian_stats(full_ds['s1'].sel(band = band, time = ts))\n",
    "            r_ds['s1'].loc[dict(time = ts, band = band)] = np.random.normal(size = n, loc = u, scale = std).reshape(shape)\n",
    "\n",
    "    r_ds = s1_to_sd(r_ds)\n",
    "\n",
    "    ds = full_ds.sel(time = im_date, method = 'nearest')\n",
    "\n",
    "    print(site_name)\n",
    "    r, b, mae, rmse, nrmse = get_stats(ds['snow_depth'], ds['lidar-sd'], nrmse = True)\n",
    "    rand_r, rand_b, rand_mae, rand_rmse, rand_nrmse = get_stats(r_ds['snow_depth'].sel(time = im_date, method = 'nearest'), r_ds['lidar-sd'], nrmse = True)\n",
    "    print(f'S1: R: {r}. RMSE: {nrmse}. RANDOM: R: {rand_r} RMSE: {rand_nrmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
