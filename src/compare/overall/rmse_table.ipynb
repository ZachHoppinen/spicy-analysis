{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spicy_snow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/rdcrlzh1/Documents/spicy-analysis/src/compare/overall/rmse_table.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rdcrlzh1/Documents/spicy-analysis/src/compare/overall/rmse_table.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m pearsonr\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rdcrlzh1/Documents/spicy-analysis/src/compare/overall/rmse_table.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rdcrlzh1/Documents/spicy-analysis/src/compare/overall/rmse_table.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspicy_snow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrieval\u001b[39;00m \u001b[39mimport\u001b[39;00m retrieval_from_parameters\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spicy_snow'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from spicy_snow.retrieval import retrieval_from_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lievens_params = [2, 0.5, 0.44]\n",
    "# wus_params = [2.5, 0.2, 0.55]\n",
    "# wus_v2_params = [1.5, 0.1, 0.59]\n",
    "\n",
    "in_dir = Path('~/spicy-snow/SnowEx-Data/').expanduser().resolve()\n",
    "data_dir = Path('~/scratch/spicy/SnowEx-Data/').expanduser().resolve()\n",
    "\n",
    "# Create parameter space\n",
    "A = np.round(np.arange(1, 3.1, 0.1), 2)\n",
    "B = np.round(np.arange(0, 2.01, 0.1), 2)\n",
    "C = np.round(np.arange(0, 1.001, 0.01), 2)\n",
    "\n",
    "def bias(x, y): return np.mean(x - y)\n",
    "\n",
    "def get_stats(x, y):\n",
    "    if type(x) == xr.DataArray: x = x.values.ravel()\n",
    "    if type(y) == xr.DataArray: y = y.values.ravel()\n",
    "    if type(x) == list: x = np.array(x)\n",
    "    if type(y) == list: y = np.array(y)\n",
    "    idx = (~np.isnan(x)) & (~np.isnan(y))\n",
    "    x, y = x[idx], y[idx]\n",
    "    r, p = pearsonr(x, y)\n",
    "    b = bias(x, y)\n",
    "    mae = mean_absolute_error(x, y)\n",
    "    rmse = mean_squared_error(x, y, squared = False)\n",
    "    return r, b, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'A' ()>\n",
      "array(1.5)\n",
      "<xarray.DataArray 'B' ()>\n",
      "array(0.)\n",
      "<xarray.DataArray 'C' ()>\n",
      "array(0.27)\n"
     ]
    }
   ],
   "source": [
    "npy_dirs = Path('/bsuhome/zacharykeskinen/scratch/spicy/param_npys')\n",
    "all_res = xr.open_dataset(npy_dirs.joinpath('grouped.nc'))\n",
    "print(all_res['pearsonr'].max(['B', 'C']).idxmax('A'))\n",
    "print(all_res['pearsonr'].max(['C', 'A']).idxmax('B'))\n",
    "print(all_res['mae'].min(['A', 'B']).idxmin('C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fp in in_dir.glob('*.nc'):\n",
    "#     ds = xr.open_dataset(fp)\n",
    "\n",
    "#     if fp.stem == 'Frasier_2020-02-11':\n",
    "#         r, b, mae, rmse = get_stats(ds['lidar-sd'], ds['snow_depth'].sel(time = '2020-02-16'))\n",
    "#         im_date = pd.to_datetime(ds.sel(time = '2020-02-16', method = 'nearest').time.values.ravel()[0])\n",
    "#     else:\n",
    "#         r, b, mae, rmse = get_stats(ds['lidar-sd'], ds['snow_depth'].sel(time = ds.attrs['lidar-flight-time'], method = 'nearest'))\n",
    "#         im_date = pd.to_datetime(ds.sel(time = ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "#     d_days = im_date - pd.to_datetime(ds.attrs['lidar-flight-time'])\n",
    "#     print(fp.stem)\n",
    "#     print(d_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "coarse_x = []\n",
    "coarse_y = []\n",
    "\n",
    "coarse_x_1k = []\n",
    "coarse_y_1k = []\n",
    "dss = {fp.stem: xr.open_dataset(fp) for fp in in_dir.glob('*.nc')}\n",
    "\n",
    "for stem, ds in dss.items():\n",
    "\n",
    "    if stem == 'Frasier_2020-02-11':\n",
    "        r, b, mae, rmse = get_stats(ds['lidar-sd'], ds['snow_depth'].sel(time = '2020-02-16'))\n",
    "        im_date = pd.to_datetime('2020-02-16')\n",
    "    else:\n",
    "        r, b, mae, rmse = get_stats(ds['lidar-sd'], ds['snow_depth'].sel(time = ds.attrs['lidar-flight-time'], method = 'nearest'))\n",
    "        im_date = pd.to_datetime(ds.sel(time = ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "    d_days = im_date - pd.to_datetime(ds.attrs['lidar-flight-time'])\n",
    "\n",
    "    site_name = stem.replace('_', ' ').split('-')[0]\n",
    "\n",
    "    # add RMSE and bias @ 90m\n",
    "    for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "        res.loc[site_name, name] = var\n",
    "\n",
    "    # for dry only\n",
    "    idx = ds['wet_snow'].sel(time = im_date, method = 'nearest') == 0\n",
    "    r, b, mae, rmse  = get_stats(ds['lidar-sd'].where(idx), ds['snow_depth'].sel(time = im_date, method = 'nearest').where(idx))\n",
    "    for name, var in zip(['RMSE'], [rmse]):\n",
    "        res.loc[site_name, name + ' (Dry)'] = var\n",
    "\n",
    "    # @ 300 m\n",
    "    ds_500 = ds.coarsen(x = 3, y = 3, boundary = 'pad').mean()\n",
    "    r, b, mae, rmse  = get_stats(ds_500['lidar-sd'], ds_500['snow_depth'].sel(time = im_date, method = 'nearest'))\n",
    "    coarse_x.append(ds_500['lidar-sd'].values.ravel())\n",
    "    coarse_y.append(ds_500['snow_depth'].sel(time = im_date, method = 'nearest').values.ravel())\n",
    "\n",
    "    for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "        res.loc[site_name, name+' @ 300m'] = var\n",
    "\n",
    "    # @ 500 m\n",
    "    ds_500 = ds.coarsen(x = 6, y = 6, boundary = 'pad').mean()\n",
    "    r, b, mae, rmse  = get_stats(ds_500['lidar-sd'], ds_500['snow_depth'].sel(time = im_date, method = 'nearest'))\n",
    "    coarse_x.append(ds_500['lidar-sd'].values.ravel())\n",
    "    coarse_y.append(ds_500['snow_depth'].sel(time = im_date, method = 'nearest').values.ravel())\n",
    "\n",
    "    for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "        res.loc[site_name, name+' @ 500m'] = var\n",
    "\n",
    "    # @ 1 km\n",
    "\n",
    "    ds_500 = ds.coarsen(x = 11, y = 11, boundary = 'pad').mean()\n",
    "    r, b, mae, rmse  = get_stats(ds_500['lidar-sd'], ds_500['snow_depth'].sel(time = im_date, method = 'nearest'))\n",
    "    coarse_x_1k.append(ds_500['lidar-sd'].values.ravel())\n",
    "    coarse_y_1k.append(ds_500['snow_depth'].sel(time = im_date, method = 'nearest').values.ravel())\n",
    "\n",
    "    for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "        res.loc[site_name, name+' @ 1km'] = var\n",
    "\n",
    "\n",
    "for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "    res.loc['All Sites', name] = all_res.sel(A = 1.5, B = 0.1, C = 0.59)[name.lower().replace(' ', '')]\n",
    "\n",
    "r, b, mae, rmse  = get_stats(np.concatenate(coarse_x).ravel(), np.concatenate(coarse_y).ravel())\n",
    "for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "    res.loc['All Sites', name+' @ 500m'] = var\n",
    "\n",
    "r, b, mae, rmse  = get_stats(np.concatenate(coarse_x_1k).ravel(), np.concatenate(coarse_y_1k).ravel())\n",
    "for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "    res.loc['All Sites', name+' @ 1km'] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dss = {fp.stem: xr.open_dataset(fp) for fp in in_dir.glob('*.nc')}\n",
    "# for cond in ['Dry', '<25% FCF', 'Dry, <25% FCF']:\n",
    "#     for looks, spatial in zip([1, 6, 11], ['', ' @ 500m', ' @ 1km']):\n",
    "\n",
    "#         xs= []\n",
    "#         ys = []\n",
    "\n",
    "#         for stem, ds in dss.items():\n",
    "#             if stem == 'Frasier_2020-02-11':\n",
    "#                 im_date = pd.to_datetime('2020-02-16')\n",
    "#             else:\n",
    "#                 im_date = pd.to_datetime(ds.sel(time = ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "#             site_name = stem.replace('_', ' ').split('-')[0].replace('Little Cottonwood', 'LCC')\n",
    "#             ds = ds.sel(time = im_date, method = 'nearest')\n",
    "\n",
    "#             ds_500 = ds.coarsen(x = looks, y = looks, boundary = 'pad').mean()\n",
    "        \n",
    "#             if cond == 'Dry':\n",
    "#                 ds_500 = ds_500.where(ds_500['wet_snow'] == 0)\n",
    "#             if cond == '<25% FCF':\n",
    "#                 ds_500 = ds_500.where(ds_500['fcf'] < 0.25)\n",
    "#             if cond == 'Dry, <25% FCF':\n",
    "#                 ds_500 = ds_500.where((ds_500['wet_snow'] == 0) & (ds_500['fcf']< 0.25))\n",
    "#             xs.extend(ds_500['lidar-sd'].values.ravel())\n",
    "#             ys.extend(ds_500['snow_depth'].values.ravel())\n",
    "        \n",
    "#         # xs, ys = np.array(xs), np.array(ys)\n",
    "\n",
    "#         if np.sum(~np.isnan(xs)) < 5:\n",
    "#             continue\n",
    "#         r, b, mae, rmse = get_stats(xs, ys)\n",
    "\n",
    "#         for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#             res.loc[f'All Sites ({cond})', name+spatial] = float(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.to_csv('/bsuhome/zacharykeskinen/spicy-analysis/results/table1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame()\n",
    "# coarse_x = []\n",
    "# coarse_y = []\n",
    "\n",
    "# coarse_x_1k = []\n",
    "# coarse_y_1k = []\n",
    "# for fp in in_dir.glob('*.nc'):\n",
    "#     ds = xr.open_dataset(fp)\n",
    "\n",
    "#     if fp.stem == 'Frasier_2020-02-11':\n",
    "#         r, b, mae, rmse = get_stats(ds['lidar-sd'], ds['snow_depth'].sel(time = '2020-02-16'))\n",
    "#         im_date = pd.to_datetime('2020-02-16')\n",
    "#     else:\n",
    "#         r, b, mae, rmse = get_stats(ds['lidar-sd'], ds['snow_depth'].sel(time = ds.attrs['lidar-flight-time'], method = 'nearest'))\n",
    "#         im_date = pd.to_datetime(ds.sel(time = ds.attrs['lidar-flight-time'], method = 'nearest').time.values.ravel()[0])\n",
    "#     d_days = im_date - pd.to_datetime(ds.attrs['lidar-flight-time'])\n",
    "\n",
    "#     site_name = fp.stem.replace('_', ' ').split('-')[0]\n",
    "#     for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#         res.loc[site_name, name] = var\n",
    "\n",
    "#     ds_500 = ds.coarsen(x = 6, y = 6, boundary = 'pad').mean()\n",
    "#     r, b, mae, rmse  = get_stats(ds_500['lidar-sd'], ds_500['snow_depth'].sel(time = im_date, method = 'nearest'))\n",
    "#     coarse_x.append(ds_500['lidar-sd'].values.ravel())\n",
    "#     coarse_y.append(ds_500['snow_depth'].sel(time = im_date, method = 'nearest').values.ravel())\n",
    "\n",
    "#     for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#         res.loc[site_name, name+' @ 500m'] = var\n",
    "\n",
    "#     ds_500 = ds.coarsen(x = 11, y = 11, boundary = 'pad').mean()\n",
    "#     r, b, mae, rmse  = get_stats(ds_500['lidar-sd'], ds_500['snow_depth'].sel(time = im_date, method = 'nearest'))\n",
    "#     coarse_x_1k.append(ds_500['lidar-sd'].values.ravel())\n",
    "#     coarse_y_1k.append(ds_500['snow_depth'].sel(time = im_date, method = 'nearest').values.ravel())\n",
    "\n",
    "#     for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#         res.loc[site_name, name+' @ 1km'] = var\n",
    "\n",
    "#     # lievens_ds = retrieval_from_parameters(xr.open_dataset(data_dir.joinpath(fp.name)), A = lievens_params[0], B = lievens_params[1], C = lievens_params[2])\n",
    "\n",
    "#     # o_r, o_b, o_mae, o_rmse = get_stats(lievens_ds['lidar-sd'], lievens_ds['snow_depth'].sel(time = im_date, method = 'nearest'))\n",
    "\n",
    "#     # res.loc[site_name, 'Lievens (2022) rmse'] = o_rmse\n",
    "#     # res.loc[site_name, 'Lievens (2022) Pearson R'] = o_r\n",
    "\n",
    "# for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#     res.loc['All Sites', name] = all_res.sel(A = 1.5, B = 0.1, C = 0.59)[name.lower().replace(' ', '')]\n",
    "# # res.loc['All Sites', 'Lievens (2022) rmse'] = all_res.sel(A = lievens_params[0], B = lievens_params[1], C = lievens_params[2])['rmse']\n",
    "# # res.loc['All Sites', 'Lievens (2022) Pearson R'] = all_res.sel(A = lievens_params[0], B = lievens_params[1], C = lievens_params[2])['pearsonr']\n",
    "\n",
    "# r, b, mae, rmse  = get_stats(np.concatenate(coarse_x).ravel(), np.concatenate(coarse_y).ravel())\n",
    "# for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#     res.loc['All Sites', name+' @ 500m'] = var\n",
    "\n",
    "# r, b, mae, rmse  = get_stats(np.concatenate(coarse_x_1k).ravel(), np.concatenate(coarse_y_1k).ravel())\n",
    "# for name, var in zip(['RMSE', 'Pearson R'], [rmse, r]):\n",
    "#     res.loc['All Sites', name+' @ 1km'] = var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spicy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
